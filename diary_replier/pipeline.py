# diary_replier/pipeline.py
from typing import Dict, Any
import os
import logging

try:
    from openai import OpenAI
    from openai import AuthenticationError, APIError, RateLimitError
except ImportError:
    OpenAI = None
    AuthenticationError = APIError = RateLimitError = Exception  # ì•ˆì „í•˜ê²Œ ëŒ€ì²´

log = logging.getLogger(__name__)

def diary_to_reply(payload, settings=None) -> Dict[str, Any]:
    data = payload.model_dump() if hasattr(payload, "model_dump") else dict(payload)
    text = (data.get("text") or "").strip()
    opts = data.get("options") or {}
    length_pref = (opts.get("length") or "both").lower()

    if not text:
        return _empty_response()

    # --- ê°„ë‹¨ ë¶„ì„ / í”Œë˜ê·¸ ---
    lower = text.lower()
    danger_words = ["ìí•´", "ì£½ê³ ", "í•´ì¹˜", "í­ë ¥"]
    safety_flag = any(w in text for w in danger_words)
    valence = "negative" if any(k in lower for k in ["í˜ë“¤", "ë¶ˆì•ˆ", "ìš°ìš¸", "ì§œì¦"]) else "neutral"
    analysis = {
        "valence": valence,
        "emotions": [],
        "keywords": [],
        "summary": text[:120] + ("..." if len(text) > 120 else ""),
    }

    # --- LLM ì‚¬ìš© ì—¬ë¶€ ê²°ì • ---
    api_key = getattr(settings, "openai_api_key", None) if settings else os.getenv("OPENAI_API_KEY")
    model_name = getattr(settings, "model_name", "gpt-4o-mini") if settings else "gpt-4o-mini"
    strict = (os.getenv("DIARY_STRICT_LLM", "0") == "1")   # 1ì´ë©´ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ì „íŒŒ

    use_llm = bool(api_key and OpenAI and not api_key.startswith("test-"))

    reply_short = None
    reply_normal = None

    if use_llm:
        try:
            client = OpenAI(api_key=api_key)
            system = "ë„ˆëŠ” ì¼ê¸°ì— ë”°ëœ»í•˜ê²Œ ë‹µì¥í•˜ëŠ” ì¹œêµ¬ì•¼. ì¡°ì–¸ì€ ì œì•ˆí˜•, ê³¼ì¥ ê¸ˆì§€, í•œêµ­ì–´."
            if length_pref in ("short", "both"):
                r = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": system},
                        {"role": "user", "content": f"ì•„ë˜ ì¼ê¸°ì— í•œ ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ ë‹µì¥í•´ì¤˜.\n\n{text}"},
                    ],
                    temperature=0.6,
                )
                reply_short = r.choices[0].message.content.strip()
            if length_pref in ("normal", "both"):
                r = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": system},
                        {"role": "user", "content": f"ì•„ë˜ ì¼ê¸°ì— 2~4ë¬¸ì¥ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ ë‹µì¥í•´ì¤˜.\n\n{text}"},
                    ],
                    temperature=0.6,
                )
                reply_normal = r.choices[0].message.content.strip()
        except (AuthenticationError, RateLimitError, APIError, Exception) as e:
            # âœ… í…ŒìŠ¤íŠ¸/ë¡œì»¬ì—ì„œ 200ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ í´ë°±ìœ¼ë¡œ ì „í™˜
            log.warning("LLM í˜¸ì¶œ ì‹¤íŒ¨, í´ë°±ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤: %s", e)
            if strict:
                # ìš´ì˜ì—ì„œ ê°•ì œ ì‹¤íŒ¨í•˜ê³  ì‹¶ì„ ë•Œë§Œ 500ë¡œ ì˜¬ë ¤ë³´ëƒ„
                raise
            reply_short, reply_normal = _fallback_replies(length_pref)

    else:
        reply_short, reply_normal = _fallback_replies(length_pref)

    return {
        "reply_short": reply_short,
        "reply_normal": reply_normal,
        "safety_flag": safety_flag,
        "flags": {"danger_words": safety_flag},
        "analysis": analysis,
    }


def _fallback_replies(length_pref: str):
    base = "ì˜¤ëŠ˜ ë§ì´ ë²„ê±°ì› ê² ì–´ìš”. ì ê¹ ì‰¬ì–´ê°€ë©° ìì‹ ì„ ëŒë´ì£¼ëŠ” ê²ƒë„ ê´œì°®ì•„ìš” ğŸŒ¿"
    r_short = r_normal = None
    if length_pref in ("short", "both"):
        r_short = "ì˜¤ëŠ˜ë„ ìˆ˜ê³  ë§ì•˜ì–´ìš”. ì ê¹ ì‰¬ë©° ë§ˆìŒì„ ë‹¤ë…ì—¬ ì£¼ì„¸ìš”."
    if length_pref in ("normal", "both"):
        r_normal = base + " ë‚´ì¼ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ê°€ë³ê²Œë§Œ ì •í•´ë³´ë©´ ë§ˆìŒì´ í•œê²° ê°€ë²¼ì›Œì§ˆ ê±°ì˜ˆìš”."
    return r_short, r_normal


def _empty_response():
    return {
        "reply_short": None,
        "reply_normal": None,
        "safety_flag": False,
        "flags": {},
        "analysis": {"valence": None, "emotions": [], "keywords": [], "summary": ""},
    }
